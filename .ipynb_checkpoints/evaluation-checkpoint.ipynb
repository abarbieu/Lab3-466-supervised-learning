{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e2e16307-4088-435a-929d-cdb3ab35a8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import json\n",
    "import sys\n",
    "from InduceC45 import c45, readFiles\n",
    "from classifier import classify, readArrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00bce1e0-f5ea-4c85-beb2-e339f4289815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeConfusion(resultDf):\n",
    "    labels = resultDf.iloc[:, -1].unique() # labels are in last column (not using result df from classify)\n",
    "    zeros = np.zeros(shape=(len(labels), len(labels)))\n",
    "    confusion = pd.DataFrame(zeros, labels, labels)\n",
    "\n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "999fb7e0-58c6-4ea9-b8a7-a3d945b765a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPrecision(confusion):\n",
    "    TP = sum([confusion.iloc[i, i] for i in range(len(confusion))])\n",
    "    bottom = confusion.values.sum()\n",
    "    return TP/bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e8d0b42-294e-4a2d-8565-ac82b3658827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possiblePrecision(confusion):\n",
    "    totalPrec = 0\n",
    "    for i, col in enumerate(confusion):\n",
    "        total = confusion[col].sum()\n",
    "        totalPrec += confusion.iloc[i, i] / total\n",
    "    \n",
    "    return totalPrec/len(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d5c051e0-8d2b-44ab-bf09-fda8732bf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcRecall(confusion):\n",
    "    TP = sum([confusion.iloc[i, i] for i in range(len(confusion))])\n",
    "    bottom = confusion.values.sum()\n",
    "    return TP/bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c3cd246c-0ff2-4117-b6f8-9506ce2b3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibleRecall(confusion):\n",
    "    totalRec = 0\n",
    "    for i, row in confusion.iterrows():\n",
    "        total = row.sum()\n",
    "        totalRec += confusion.loc[i, i] / total\n",
    "    \n",
    "    return totalRec / len(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3c786686-6155-43b0-b24d-6e0eca302698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcPf(confusion):\n",
    "    totalPf = 0\n",
    "    diagonal = sum([confusion.iloc[i, i] for i in range(len(confusion))])\n",
    "    for i, col in enumerate(confusion):\n",
    "        FP = confusion[col].sum()\n",
    "        TN = diagonal - confusion.iloc[i, i]\n",
    "        totalPf += FP/(FP + TN)\n",
    "\n",
    "    return totalPf/len(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3764c3bd-958a-470f-8c46-e753a143eca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcF(recall, precision):\n",
    "    return (2 * precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fe38ad07-3b0b-4234-8d10-2fba5ee40f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "numSplits = 4.0\n",
    "datafile = 'houses.csv'\n",
    "restrictions = 'restr.txt'\n",
    "df, tmp, isLabeled = readFiles(datafile,restrictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b41058cd-bd85-4f9b-b2d8-fe64d7ac2c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records Classifed:  4\n",
      "Total Classified Correctly:  4\n",
      "Total Classified Incorrectly:  0\n",
      "Accuracy:  1.0\n",
      "Error Rate:  0.0\n",
      "Total Records Classifed:  4\n",
      "Total Classified Correctly:  3\n",
      "Total Classified Incorrectly:  1\n",
      "Accuracy:  0.75\n",
      "Error Rate:  0.25\n",
      "Total Records Classifed:  4\n",
      "Total Classified Correctly:  4\n",
      "Total Classified Incorrectly:  0\n",
      "Accuracy:  1.0\n",
      "Error Rate:  0.0\n",
      "Total Records Classifed:  4\n",
      "Total Classified Correctly:  4\n",
      "Total Classified Incorrectly:  0\n",
      "Accuracy:  1.0\n",
      "Error Rate:  0.0\n",
      "This is vals:  [3.75, 0.25]\n",
      "This is one possible calculation of Precision:  0.95\n",
      "This is one possible calculation of recall:  0.9285714285714286\n",
      "This is another precision:  0.9375\n",
      "This is another recall:  0.9375\n",
      "This is possibly PF:  0.5125\n",
      "     N    Y\n",
      "N  9.0  0.0\n",
      "Y  1.0  6.0\n",
      "This is average accuracy:  0.9375\n",
      "This is overall accuracy:  0.234375\n",
      "This is average error rate:  0.0625\n",
      "This is overall error rate:  0.015625\n",
      "0 0    2\n",
      "1    N\n",
      "Name: 0, dtype: object\n",
      "1 0    3\n",
      "1    Y\n",
      "Name: 1, dtype: object\n",
      "2 0    4\n",
      "1    N\n",
      "Name: 2, dtype: object\n",
      "3 0    5\n",
      "1    N\n",
      "Name: 3, dtype: object\n",
      "4 0    6\n",
      "1    N\n",
      "Name: 4, dtype: object\n",
      "5 0    7\n",
      "1    Y\n",
      "Name: 5, dtype: object\n",
      "6 0    8\n",
      "1    Y\n",
      "Name: 6, dtype: object\n",
      "7 0    9\n",
      "1    N\n",
      "Name: 7, dtype: object\n",
      "8 0    10\n",
      "1     Y\n",
      "Name: 8, dtype: object\n",
      "9 0    11\n",
      "1     N\n",
      "Name: 9, dtype: object\n",
      "10 0    12\n",
      "1     Y\n",
      "Name: 10, dtype: object\n",
      "11 0    13\n",
      "1     N\n",
      "Name: 11, dtype: object\n",
      "12 0    14\n",
      "1     Y\n",
      "Name: 12, dtype: object\n",
      "13 0    15\n",
      "1     Y\n",
      "Name: 13, dtype: object\n",
      "14 0    16\n",
      "1     N\n",
      "Name: 14, dtype: object\n",
      "15 0    17\n",
      "1     N\n",
      "Name: 15, dtype: object\n",
      "BDR    4\n",
      "BSM    N\n",
      "FLP    T\n",
      "LOC    N\n",
      "VIS    N\n",
      "Name: 16, dtype: object\n"
     ]
    }
   ],
   "source": [
    "splits = np.array_split(df, numSplits)\n",
    "final=[]\n",
    "confusion = initializeConfusion(df)\n",
    "vals = [0, 0] # holds the accuracy and error rate\n",
    "for i in range(len(splits)):\n",
    "    training = pd.concat([s for j,s in enumerate(splits) if j!=i])\n",
    "    split = splits[i]\n",
    "    final += (classify(confusion, vals, split, c45(training,training.columns[:-1], 0.2), silent=True, labeled=isLabeled))\n",
    "\n",
    "if isLabeled:\n",
    "    print(\"This is vals: \", vals)\n",
    "    print(\"This is one possible calculation of Precision: \", possiblePrecision(confusion))\n",
    "    print(\"This is one possible calculation of recall: \", possibleRecall(confusion))\n",
    "    print(\"This is another precision: \", calcPrecision(confusion))\n",
    "    print(\"This is another recall: \", calcRecall(confusion))\n",
    "    print(\"This is possibly PF: \", calcPf(confusion))\n",
    "    print(confusion)\n",
    "    \n",
    "    avgAccuracy = vals[0]/numSplits\n",
    "    overallAccuracy = vals[0]/len(df)\n",
    "    \n",
    "    avgErrorRate = vals[1]/numSplits\n",
    "    overallErrorRate = vals[1]/len(df)\n",
    "    \n",
    "    print(\"This is average accuracy: \" , avgAccuracy)\n",
    "    print(\"This is overall accuracy: \", overallAccuracy)\n",
    "    print(\"This is average error rate: \", avgErrorRate)\n",
    "    print(\"This is overall error rate: \", overallErrorRate)\n",
    "\n",
    "\n",
    "final = pd.DataFrame(final)\n",
    "for i, row in final.iterrows():\n",
    "    print(i, row)\n",
    "print(df.loc[16])\n",
    "# j=0\n",
    "# ratio=len(df)/numSplits\n",
    "# for i,row in df.iterrows():\n",
    "#     if j%ratio == 0:\n",
    "#         print(df[:)\n",
    "#     j+=1\n",
    "    \n",
    "# print(len(df), df)\n",
    "# for i in range(len(df),len(df)/numSplits):\n",
    "#     print(i)\n",
    "# for split in splits:\n",
    "#     print(split)\n",
    "#     print(c45(split,split.columns[:-1], 0.2))\n",
    "# classify(df, induceC45(\"houses.csv\"), silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4adbcb96-ef6a-4784-b17c-f8c1aac6c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bbfa8ac-f7bb-4c68-ab3a-8d6811a2c0eb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
